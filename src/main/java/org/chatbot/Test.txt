#!/usr/bin/env python3
from __future__ import annotations
import argparse, json, math, os, re, sys
from typing import List, Tuple, Optional

import psycopg2
from pgvector.psycopg2 import register_vector

# ---------- DB ----------
def _connect():
    conn = psycopg2.connect(
        host=os.getenv("PGHOST","localhost"),
        port=int(os.getenv("PGPORT","5432")),
        dbname=os.getenv("PGDATABASE"),
        user=os.getenv("PGUSER"),
        password=os.getenv("PGPASSWORD"),
    )
    register_vector(conn)
    return conn

# ---------- helpers ----------
def parse_embedding_string(s: Optional[str], expected_dim: int) -> Optional[List[float]]:
    if not s: return None
    s = s.strip()
    if s.startswith("[") and s.endswith("]"):
        s = s[1:-1]
    parts = re.split(r"[,\s]+", s.strip())
    vec = [float(x) for x in parts if x]
    if len(vec) != expected_dim:
        raise ValueError(f"Embedding dim {len(vec)} != expected {expected_dim}")
    n = math.sqrt(sum(x*x for x in vec)) or 1.0
    return [x/n for x in vec]

def _tags_from_query(q: str) -> List[str]:
    ql = q.lower()
    tags = []
    if re.search(r"\bupgrade|bump|migrate|version\b", ql): tags.append("upgrade")
    if re.search(r"\blogging|logback|log4j|slf4j\b", ql): tags.append("logging")
    if "python" in ql: tags.append("python")
    if "java" in ql: tags.append("java")
    if "confluence" in ql: tags.append("confluence")
    return tags or ["__none__"]

def _keyword_candidates(q: str) -> List[str]:
    toks = re.findall(r"[a-z0-9][a-z0-9._\-]+", q.lower())
    toks = [t for t in toks if len(t) >= 3]
    return list(dict.fromkeys(toks))[:20] or ["__none__"]

# ---------- SQL: candidate collections ----------
# With vector (hybrid) — filters by allowed kb_types / names if provided (empty arrays mean “no filter”)
CANDIDATE_COLLECTIONS_SQL = """
SET pg_trgm.similarity_threshold = 0.25;
WITH allowed AS (
  SELECT id, name, kb_type
  FROM kb_collections
  WHERE (cardinality(%s::text[]) = 0 OR kb_type = ANY(%s::text[]))
    AND (cardinality(%s::text[]) = 0 OR name = ANY(%s::text[]))
),
vec AS (
  SELECT collection_id, 1 - (embedding <=> %s) AS vscore
  FROM kb_chunks
  WHERE collection_id IN (SELECT id FROM allowed)
  ORDER BY embedding <=> %s
  LIMIT 1000
),
lex AS (
  SELECT collection_id, GREATEST(similarity(content, %s), 0) AS lscore
  FROM kb_chunks
  WHERE collection_id IN (SELECT id FROM allowed) AND content % %s
  ORDER BY lscore DESC
  LIMIT 1000
),
unioned AS (
  SELECT collection_id, vscore, 0::float AS lscore FROM vec
  UNION ALL
  SELECT collection_id, 0::float, lscore FROM lex
),
agg AS (
  SELECT collection_id,
         MAX(vscore) AS vscore,
         MAX(lscore) AS lscore,
         (0.7*MAX(vscore) + 0.3*MAX(lscore)) AS fused
  FROM unioned
  GROUP BY collection_id
)
SELECT c.id, c.name, c.kb_type, a.fused
FROM agg a JOIN kb_collections c ON c.id=a.collection_id
ORDER BY a.fused DESC
LIMIT %s;
"""

# Lexical-only fallback (no embedding provided)
CANDIDATE_COLLECTIONS_LEX_SQL = """
SET pg_trgm.similarity_threshold = 0.25;
WITH allowed AS (
  SELECT id, name, kb_type
  FROM kb_collections
  WHERE (cardinality(%s::text[]) = 0 OR kb_type = ANY(%s::text[]))
    AND (cardinality(%s::text[]) = 0 OR name = ANY(%s::text[]))
),
lex AS (
  SELECT collection_id, GREATEST(similarity(content, %s), 0) AS lscore
  FROM kb_chunks
  WHERE collection_id IN (SELECT id FROM allowed) AND content % %s
  ORDER BY lscore DESC
  LIMIT 2000
),
agg AS (
  SELECT collection_id, MAX(lscore) AS lscore
  FROM lex
  GROUP BY collection_id
)
SELECT c.id, c.name, c.kb_type, a.lscore AS fused
FROM agg a JOIN kb_collections c ON c.id=a.collection_id
ORDER BY fused DESC
LIMIT %s;
"""

# ---------- SQL: retrieve within selected collections (hybrid with boosts) ----------
HYBRID_WITHIN_SQL = """
WITH vec AS (
  SELECT id, 1 - (embedding <=> %s) AS vscore
  FROM kb_chunks
  WHERE collection_id = ANY(%s::bigint[])
  ORDER BY embedding <=> %s
  LIMIT 200
),
lex AS (
  SET pg_trgm.similarity_threshold = 0.25;
  SELECT id, GREATEST(similarity(content, %s), 0) AS lscore
  FROM kb_chunks
  WHERE collection_id = ANY(%s::bigint[]) AND content % %s
  ORDER BY lscore DESC
  LIMIT 200
),
unioned AS (
  SELECT id, vscore, 0::float AS lscore FROM vec
  UNION ALL
  SELECT id, 0::float, lscore FROM lex
),
agg AS (
  SELECT id,
         MAX(vscore) AS vscore,
         MAX(lscore) AS lscore,
         (0.7*MAX(vscore) + 0.3*MAX(lscore)
          + 0.08*MAX(CASE WHEN jsonb_exists_any(kb_chunks.metadata->'tags', %s::text[]) THEN 1 ELSE 0 END)
          + 0.05*MAX(CASE WHEN (kb_chunks.metadata->'keywords') ?| %s::text[] THEN 1 ELSE 0 END)
          + 0.04*AVG(COALESCE( (kb_chunks.metadata->>'folder_boost')::float, 0))
         ) AS fused
  FROM unioned
  JOIN kb_chunks USING (id)
  GROUP BY id
)
SELECT c.id, c.collection_id, c.external_id, c.symbol_kind,
       a.vscore, a.lscore, a.fused, c.content
FROM agg a
JOIN kb_chunks c USING (id)
ORDER BY a.fused DESC
LIMIT %s;
"""

VEC_ONLY_WITHIN_SQL = """
SELECT id, collection_id, external_id, symbol_kind,
       1 - (embedding <=> %s) AS vscore, content
FROM kb_chunks
WHERE collection_id = ANY(%s::bigint[])
ORDER BY embedding <=> %s
LIMIT %s;
"""

# ---------- core ----------
def pick_collections(conn, query: str, qvec: Optional[List[float]],
                     allow_types: List[str], allow_names: List[str],
                     top_collections: int) -> List[Tuple[int,str,str,float]]:
    allow_types = allow_types or []
    allow_names = allow_names or []
    with conn.cursor() as cur:
        if qvec is not None:
            params = (allow_types, allow_types, allow_names, allow_names, qvec, qvec, query, query, top_collections)
            cur.execute(CANDIDATE_COLLECTIONS_SQL, params)
        else:
            params = (allow_types, allow_types, allow_names, allow_names, query, query, top_collections)
            cur.execute(CANDIDATE_COLLECTIONS_LEX_SQL, params)
        return [(r[0], r[1], r[2], float(r[3])) for r in cur.fetchall()]

def retrieve_within(conn, query: str, qvec: Optional[List[float]],
                    collection_ids: List[int], k: int) -> List[tuple]:
    if not collection_ids: return []
    if qvec is not None:
        tags = _tags_from_query(query)
        keys = _keyword_candidates(query)
        params = (qvec, collection_ids, qvec, query, collection_ids, query, tags, keys, k)
        with conn.cursor() as cur:
            cur.execute(HYBRID_WITHIN_SQL, params)
            return cur.fetchall()
    else:
        params = (query, collection_ids, query, k)  # use lexical-only by swapping to vec-only? Here we do trigram-only by cheating via vector-less path
        # Simpler: still use lex path, emulate with HYBRID via zero vec? We'll just do lex-only quick query:
        with conn.cursor() as cur:
            cur.execute("SET pg_trgm.similarity_threshold = 0.25;")
            cur.execute("""
              SELECT id, collection_id, external_id, symbol_kind,
                     GREATEST(similarity(content, %s),0) AS lscore, content
              FROM kb_chunks
              WHERE collection_id = ANY(%s::bigint[])
                AND content % %s
              ORDER BY lscore DESC
              LIMIT %s;
            """, params)
            return cur.fetchall()

def build_context(rows: List[tuple], collections_meta: List[Tuple[int,str,str,float]], query: str) -> str:
    # Group by collection for a tidy context
    by_coll: dict[int, List[tuple]] = {}
    for r in rows:
        coll_id = r[1] if len(r) >= 2 else None
        by_coll.setdefault(coll_id, []).append(r)

    name_map = {cid: (name, kbt, score) for cid, name, kbt, score in collections_meta}
    parts = [f"Query: {query}\n"]

    for cid, items in by_coll.items():
        name, kbt, cscore = name_map.get(cid, (f"collection:{cid}", "unknown", 0.0))
        parts.append(f"== Collection: {name}  (type={kbt}, routed_score={cscore:.3f}) ==")
        for r in items[:5]:
            if len(r) == 8:  # hybrid shape
                _id, _coll, ext, kind, v, l, f, content = r
                parts.append(f"- [{kind or 'doc'}] {ext}  (score={f:.3f})")
                # include a tiny excerpt
                snippet = "\n".join((content or "").splitlines()[:30])
                parts.append(snippet)
                parts.append("")
            else:            # lexical-only fallback shape
                _id, _coll, ext, kind, s, content = r
                parts.append(f"- [{kind or 'doc'}] {ext}  (score={float(s):.3f})")
                snippet = "\n".join((content or "").splitlines()[:30])
                parts.append(snippet)
                parts.append("")
    return "\n".join(parts).strip()

# ---------- CLI ----------
def main():
    ap = argparse.ArgumentParser(description="Auto-route across multiple collections and retrieve LLM context.")
    ap.add_argument("--query", required=True, help="Natural query, e.g., 'upgrade chassis to latest from 3.0.0'")
    ap.add_argument("--embedding", default=None, help="Query embedding as JSON/CSV string (optional).")
    ap.add_argument("--embedding-dim", type=int, default=1024)
    ap.add_argument("--top-collections", type=int, default=3)
    ap.add_argument("--k", type=int, default=12)
    ap.add_argument("--allow-types", default="", help="Comma-separated kb_types to include (optional).")
    ap.add_argument("--allow-names", default="", help="Comma-separated collection names to include (optional).")
    args = ap.parse_args()

    qvec = parse_embedding_string(args.embedding, args.embedding_dim) if args.embedding else None
    allow_types = [s.strip() for s in args.allow_types.split(",") if s.strip()]
    allow_names = [s.strip() for s in args.allow_names.split(",") if s.strip()]

    conn = _connect()
    try:
        colls = pick_collections(conn, args.query, qvec, allow_types, allow_names, args.top_collections)
        if not colls:
            print("No candidate collections found.")
            return
        ids = [c[0] for c in colls]
        rows = retrieve_within(conn, args.query, qvec, ids, args.k)
        context = build_context(rows, colls, args.query)
        print(context)
        print("\n[auto] candidate collections:", " | ".join(f"{cid}:{name}({kbt})" for cid,name,kbt,_ in colls))
    finally:
        conn.close()

if __name__ == "__main__":
    main()
